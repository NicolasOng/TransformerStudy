{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 # how many predictions the model can make in parallel\n",
    "block_size = 5 # context length\n",
    "token_embedding_size = 384\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data, Token -> Integer mapping, and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num characters in dataset: 1,115,394\n",
      "length of dataset in characters: 1,115,394\n",
      "all the unique characters: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 65\n",
      "train has 1,003,854 tokens\n",
      "val has 111,540 tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Creates the char to int token embedding based on the file chosen.\n",
    "\n",
    "based on:\n",
    "https://github.com/karpathy/nanoGPT/blob/master/data/shakespeare_char/prepare.py\n",
    "https://github.com/karpathy/ng-video-lecture/blob/master/gpt.py\n",
    "'''\n",
    "\n",
    "# get the text from the text file\n",
    "input_file_path = \"./data/tinyshakespeare.txt\"\n",
    "with open(input_file_path, 'r') as f:\n",
    "    data = f.read()\n",
    "print(f\"num characters in dataset: {len(data):,}\")\n",
    "\n",
    "# get all the unique characters\n",
    "chars = sorted(set(data))\n",
    "print(f\"length of dataset in characters: {len(data):,}\")\n",
    "\n",
    "# get all the unique characters that occur in this text\n",
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", ''.join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# create the train and test splits\n",
    "encoded_data = torch.tensor(encode(data), dtype=torch.long)\n",
    "n = int(len(encoded_data)*0.9)\n",
    "train_data = encoded_data[:n]\n",
    "val_data = encoded_data[n:]\n",
    "\n",
    "print(f\"train has {len(train_data):,} tokens\")\n",
    "print(f\"val has {len(val_data):,} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    '''\n",
    "    Generates two tensors. Each of size (batch, block).\n",
    "    x is [batch] character sequences of length [block], each character encoded as a token/int.\n",
    "    y is the targets of the character sequences in x.\n",
    "    For example, for x=[abcde,fghij], y=[bcdef,ghijk],\n",
    "    given the sequence x[n][:m], you want to predict y[n][m]\n",
    "    '''\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 41, 53, 59, 50],\n",
      "        [ 0,  0, 29, 33, 17]])\n",
      "tensor([[41, 53, 59, 50, 42],\n",
      "        [ 0, 29, 33, 17, 17]])\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(\"train\")\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Embeddings and Position Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token and Position Embeddings\n",
    "token_embedding_table = nn.Embedding(vocab_size, token_embedding_size)\n",
    "\n",
    "def compute_positional_encoding(pos, dim, d_model):\n",
    "    '''\n",
    "    Here are the formulas for the positional encodings from the paper\n",
    "      PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "      PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "    \n",
    "    PE(pos, 2i) is for the even elements of the position encoding.\n",
    "    pos is the position in the sequence\n",
    "    d_model is the length of the position encoding\n",
    "    2i or 2i+1 is the element index into the position encoding\n",
    "    '''\n",
    "    if (dim % 2) == 0:\n",
    "        pe = math.sin(pos / (10000 ** (dim / d_model)))\n",
    "    else:\n",
    "        pe = math.cos(pos / (10000 ** ((dim - 1) / d_model)))\n",
    "    return pe\n",
    "\n",
    "def generate_positional_encodings(seq_len, d_model):\n",
    "    '''\n",
    "    This function uses the compute_positional_encoding function\n",
    "    to generate the (block, embed_dim) positional encoding.\n",
    "    This is added to each batch in the (batch, block, embed_dim) token embedding.\n",
    "    '''\n",
    "    pe = torch.zeros(seq_len, d_model)\n",
    "    for pos in range(seq_len):\n",
    "        for dim in range(d_model):\n",
    "            pe[pos, dim] = compute_positional_encoding(pos, dim, d_model)\n",
    "    return pe\n",
    "\n",
    "def positional_encoding(seq_len, d_model):\n",
    "    # Create a positional encoding matrix of shape (seq_len, d_model)\n",
    "    # This is a more efficient way of doing generate_positional_encodings,\n",
    "    # although it generates slightly different due to floating pt calculations.\n",
    "    pe = torch.zeros(seq_len, d_model)\n",
    "    position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0.0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "    \n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    \n",
    "    return pe\n",
    "\n",
    "def embeddings(x):\n",
    "    #token embeddings (batch, block, embedding_dim)\n",
    "    token_embeddings = token_embedding_table(x)\n",
    "    batch, block, embedding_dim = token_embeddings.shape\n",
    "    #positional encoding (block, embedding_dim)\n",
    "    positional_encodings = positional_encoding(block, embedding_dim)\n",
    "    return token_embeddings + positional_encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0909,  0.2569,  0.0254,  ...,  0.2936,  1.3609,  0.9250],\n",
      "         [ 1.6292, -0.2421,  0.6794,  ...,  1.4893,  0.6341,  1.3685],\n",
      "         [-0.7493, -1.4487,  1.3906,  ...,  1.2283,  0.5427,  1.0755],\n",
      "         [ 0.9133, -1.9406,  2.8327,  ...,  0.5540, -0.3253,  1.5460],\n",
      "         [ 0.0154, -1.6042,  1.9325,  ...,  0.5540, -0.3252,  1.5460]],\n",
      "\n",
      "        [[ 1.8882,  1.1989,  1.6346,  ..., -0.0656, -0.0731, -0.1586],\n",
      "         [ 2.3591, -0.4629,  2.1529,  ..., -1.3799, -1.3144,  0.6742],\n",
      "         [ 0.8493,  0.8104, -0.1283,  ...,  0.4572,  0.8704,  2.1054],\n",
      "         [ 0.6559, -1.4095,  0.4233,  ...,  2.2858,  0.0920, -0.0469],\n",
      "         [ 0.8315, -1.7669, -0.1141,  ..., -1.3999, -1.4239,  1.7783]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(\"train\")\n",
    "z = embeddings(x)\n",
    "print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
